{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16046403",
   "metadata": {},
   "source": [
    "The notebook provides a demonstration of dataset construction, and model training and prediction do not require running the following code again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6e0e3",
   "metadata": {},
   "source": [
    "# Load Data from Database\n",
    "\n",
    "\n",
    "This step allows you to merge multiple datasets from a specified path and remove invalid fluorescent molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbb857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from FLAME.dataprocess.utils import load_data\n",
    "\n",
    "df_origin = load_data('data/Database/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07607777",
   "metadata": {},
   "source": [
    "# Solvent Process\n",
    "\n",
    "We observed that some open-source datasets contain a large number of uncommon solvent types. \n",
    "To address this, we processed the data by removing solvent types with fewer than 10 occurrences \n",
    "in the dataset, along with their associated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FLAME.dataprocess.utils import get_solmap, get_solvent_df\n",
    "\n",
    "solvents = set(df_origin.solvent.values)\n",
    "print('Total %d solvents' %(len(solvents)))\n",
    "\n",
    "solmap, mix_solvent, unknow_solvent = get_solmap(solvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete only smiles\n",
    "df, df_mix = get_solvent_df(df_origin, solmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e784d",
   "metadata": {},
   "source": [
    "# Duplication process\n",
    "\n",
    "During the redundant data processing, we set difference thresholds for each parameter. The difference threshold is 5 nm for λabs and λem, 0.1 for ΦPL, and 0.02 for log10 εmax. For each fluorophore-solvent pair, redundant data from differ-ent resources were removed if exceeding the difference threshold, and the average value of the remaining data was put into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis the duplicated data\n",
    "delta_a = []\n",
    "delta_e = []\n",
    "delta_p = []\n",
    "delta_ep = []\n",
    "print('start Merge Duplicate data')\n",
    "for smi, sdf in df.groupby(['smiles', 'solvent']):\n",
    "    if len(sdf) > 1:\n",
    "        delta_a.append(max(sdf['absorption/nm'])-min(sdf['absorption/nm']))\n",
    "        delta_e.append(max(sdf['emission/nm'])-min(sdf['emission/nm']))\n",
    "        delta_p.append(max(sdf['plqy'])-min(sdf['plqy']))\n",
    "        delta_ep.append(max(sdf['e/m-1cm-1'])-min(sdf['e/m-1cm-1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72006424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FLAME.dataprocess.utils import merge_item\n",
    "\n",
    "#delta = 5\n",
    "ndf = []\n",
    "print('start Merge Duplicated data')\n",
    "for smi, sdf in df.groupby(['smiles', 'solvent']):\n",
    "    if len(sdf) > 1:\n",
    "        ssdf = merge_item(sdf)\n",
    "    else:\n",
    "        ssdf = sdf.copy()\n",
    "    if not len(ssdf):\n",
    "        print('drop item')\n",
    "        continue\n",
    "    if len(ndf):\n",
    "        ndf = pd.concat([ndf, ssdf])\n",
    "    else:\n",
    "        ndf = ssdf\n",
    "\n",
    "print(len(df),' before')\n",
    "print(len(ndf),' after')\n",
    "ndf = ndf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935379a",
   "metadata": {},
   "source": [
    "# Make Scaffold Tag\n",
    "\n",
    "This step aims to label all fluorescent molecules in the dataset according to our proposed \n",
    "16 types of fluorescent molecular scaffolds. This enables a better understanding of the \n",
    "scaffold types of molecules within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f45268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from FLAME.flsf.scaffold import scaffold\n",
    "\n",
    "\n",
    "dt = [(k,Chem.MolFromSmiles(m)) for k,v in scaffold.items() for m in v]\n",
    "scaff_dict = dict([(k,v) for v,k in enumerate(scaffold.keys())])\n",
    "patterns = pd.DataFrame({\n",
    "    'idx':[scaff_dict[x] for x in list(zip(*dt))[0]],\n",
    "    'mol':list(zip(*dt))[1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a988862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ndf['tag'] = -1\n",
    "for i in tqdm(range(len(ndf))):\n",
    "    if ndf.loc[i, 'tag'] != -1:\n",
    "        continue\n",
    "    mol = Chem.MolFromSmiles(ndf.loc[i].smiles)\n",
    "    for _, patt in patterns.iterrows():\n",
    "        if mol.HasSubstructMatch(patt.mol):\n",
    "            ndf.loc[i, 'tag'] = patt.idx\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export scaffold\n",
    "for k,v in scaffold.items():\n",
    "    writer = Chem.SDWriter(f'data/scaffold/{k}.sdf')\n",
    "    for i, smi in enumerate(v):\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        writer.write(mol)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaff_dict_r = dict([(str(v),k) for k,v in scaff_dict.items()])\n",
    "scaff_dict_r['-1'] = 'None'\n",
    "for k,v in dict(ndf.groupby(['tag']).size()).items():\n",
    "    print(k, scaff_dict_r[str(k)], v)\n",
    "ndf['tag_name'] = [scaff_dict_r[str(t)] for t in ndf.tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cae88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw\n",
    "\n",
    "smis = dict(ndf[ndf.tag==-1].sample(n=20).smiles)\n",
    "mols = [Chem.MolFromSmiles(m) for m in smis.values()]\n",
    "Draw.MolsToGridImage(mols, molsPerRow=5, legends=np.array(list(smis.keys())).astype('str').tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8303f5c1",
   "metadata": {},
   "source": [
    "# DataSet Process\n",
    "\n",
    "This is an example demonstrating how to split a given dataset into training, validation, \n",
    "and test sets in a 7:1:2 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Split\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/FluoDB-Lite.csv')\n",
    "df = df[df['smiles'].str.find('.')==-1]\n",
    "df = df.sample(frac=1.)\n",
    "df.iloc[:(len(df)*7)//10, -1] = 'train'\n",
    "df.iloc[(len(df)*7)//10:(len(df)*8)//10, -1] = 'valid'\n",
    "df.iloc[(len(df)*8)//10:, -1] = 'test'\n",
    "df = df.sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process FluoDB dataset\n",
    "target_dict = {\n",
    "            'abs': 'absorption/nm',\n",
    "            'emi':'emission/nm',\n",
    "            'plqy':'plqy',\n",
    "            'e':'e/m-1cm-1'\n",
    "        }\n",
    "target = 'abs'\n",
    "df_target = df[df[target_dict[target]]>0]\n",
    "df_target.rename(columns={target_dict[target]:target}, inplace = True)\n",
    "df_target[df_target['split']=='train'].loc[:,['smiles', 'solvent', target]].to_csv(f'data/FluoDB/{target}_train.csv', index=False)\n",
    "df_target[df_target['split']=='test'].loc[:,['smiles', 'solvent', target]].to_csv(f'data/FluoDB/{target}_test.csv', index=False)\n",
    "df_target[df_target['split']=='valid'].loc[:,['smiles', 'solvent', target]].to_csv(f'data/FluoDB/{target}_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd61ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Deep4Chem dataset\n",
    "\n",
    "deep4chem_df = df[df['source'].str.find('Deep4Chem')>-1]\n",
    "target_idx = 3\n",
    "deep4chem_df_target = deep4chem_df[deep4chem_df.iloc[:,target_idx]>0]\n",
    "# deep4chem_df_target = deep4chem_df_target.iloc[:,[4,5,-1,target_idx]] # [ smiles, solvent, split, target]\n",
    "deep4chem_df_target.rename(columns={list(target_dict.values())[target_idx]:list(target_dict.keys())[target_idx]}, inplace = True)\n",
    "deep4chem_df_target[deep4chem_df_target['split']=='train'].loc[:,['smiles', 'solvent', target]].to_csv(f'data/deep4chem{target}_train.csv', index=False)\n",
    "deep4chem_df_target[deep4chem_df_target['split']=='test'].loc[:,['smiles', 'solvent', target]].to_csv(f'data/deep4chem/{target}_test.csv', index=False)\n",
    "deep4chem_df_target[deep4chem_df_target['split']=='valid'].loc[:,['smiles', 'solvent', target]].to_csv(f'data/deep4chem/{target}_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5506c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process GBRT dataset\n",
    "import pandas as pd\n",
    "\n",
    "from FLAME.dataprocess.gbrt import get_GBRT_data\n",
    "\n",
    "database = 'FluoDB'\n",
    "target = 'abs'\n",
    "split = 'test'\n",
    "train_df = pd.read_csv(f'data/{database}/{target}_{split}.csv')\n",
    "train_df = get_GBRT_data(train_df, feature_save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b8320",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# process schnet dataset\n",
    "import sys\n",
    "import os\n",
    "from ase.db import connect\n",
    "import pandas as pd\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "from ase import Atoms\n",
    "from tqdm import tqdm\n",
    "from FLAME.schnetpack.data import AtomsData\n",
    "from FLAME.schnetpack.environment import SimpleEnvironmentProvider\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def valid_atoms(\n",
    "    atoms,\n",
    "    environment_provider=SimpleEnvironmentProvider(),\n",
    "    collect_triples=False,\n",
    "    centering_function=None,\n",
    "):\n",
    "    inputs = {}\n",
    "    atoms.numbers.astype(np.dtype('int'))\n",
    "    atoms.positions.astype(np.dtype('float32'))\n",
    "\n",
    "    # get atom environment\n",
    "    nbh_idx, offsets = environment_provider.get_environment(atoms)\n",
    "\n",
    "    # Get neighbors and neighbor mask\n",
    "    nbh_idx.astype(np.dtype('int'))\n",
    "    # Get cells\n",
    "    np.array(atoms.cell.array, dtype=np.dtype('float32'))\n",
    "    offsets.astype(np.dtype('float32'))\n",
    "    return True\n",
    "\n",
    "def numpyfy_dict(data):\n",
    "    for k, v in data.items():\n",
    "        if type(v) in [int, float]:\n",
    "            v = np.array([v])\n",
    "        if v.shape == ():\n",
    "            v = v[np.newaxis]\n",
    "        data[k] = v\n",
    "    return data\n",
    "\n",
    "def get_center_of_mass(atoms):\n",
    "    masses = atoms.get_masses()\n",
    "#    print(atoms)\n",
    "    return np.dot(masses, atoms.arrays[\"positions\"]) / masses.sum()\n",
    "\n",
    "def smiles2coord(smi, conf_num=3):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    mol = Chem.AddHs(mol)\n",
    "#     smiles = Chem.MolToSmiles(mol)\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "    coords = []\n",
    "    for i in range(conf_num):\n",
    "        AllChem.EmbedMolecule(mol)\n",
    "        data = Chem.MolToXYZBlock(mol)\n",
    "        coord = np.array([x[2:].strip().split() for x in data.strip().split('\\n')[2:]]).astype(float)\n",
    "        coords.append(coord)\n",
    "    species = data.split()[1::4]\n",
    "    return coords, species\n",
    "\n",
    "def get_schnet_data(smiles, target, indices, save_path='', conf_num=1):\n",
    "    if len(save_path) == 0:\n",
    "        save_path = 'data/schnet/data.db'\n",
    "    available_properties = [\"energy\", \"indices\"]\n",
    "    atoms_list = []\n",
    "    property_list = []\n",
    "    energies = target\n",
    "    for idx,smi in tqdm(enumerate(smiles)):\n",
    "        positions, species = smiles2coord(smi, conf_num=conf_num)\n",
    "        species = ''.join(species)\n",
    "        if len(species) == 0:\n",
    "            print(smi)\n",
    "            continue\n",
    "        for i in range(conf_num):\n",
    "            atm = Atoms(species, positions[i])\n",
    "#             valid_atoms(atm)\n",
    "#             nbh_idx, offsets = environment.get_environment(atm)\n",
    "#             ct = get_center_of_mass(atm)\n",
    "            try:\n",
    "                energy = energies[idx]\n",
    "                properties = {\"energy\": energy, \"indices\":indices[idx]}\n",
    "                atoms_list.append(atm)\n",
    "                property_list.append(properties)\n",
    "            except:\n",
    "                print(smi)\n",
    "                break\n",
    "\n",
    "    key_value_pairs_list = [dict() for _ in range(len(atoms_list))]\n",
    "\n",
    "    with connect(save_path) as conn:\n",
    "        for at, prop, kv_pair in tqdm(zip(atoms_list, property_list, key_value_pairs_list)):\n",
    "            data = {}\n",
    "            # add available properties to database\n",
    "            for pname in available_properties:\n",
    "                try:\n",
    "                    data[pname] = prop[pname]\n",
    "                except:\n",
    "                    raise Exception(\"Required property missing:\" + pname)\n",
    "            # transform to np.ndarray\n",
    "            data = numpyfy_dict(data)\n",
    "            conn.write(at, data=data, key_value_pairs=kv_pair)\n",
    "\n",
    "db = 'FluoDB'\n",
    "target = 'abs'\n",
    "split = 'test'\n",
    "schnet_df = pd.read_csv(f'data/{db}/{target}_{split}.csv')\n",
    "\n",
    "schnet_df = schnet_df[schnet_df['absorption/nm']>0]\n",
    "schnet_df = schnet_df[schnet_df['smiles'].str.find('+')==-1]\n",
    "schnet_df = schnet_df[schnet_df['smiles'].str.find('-')==-1]\n",
    "schnet_df = schnet_df[schnet_df['smiles'].str.len() < 40] # schnet cannot process molecules too large\n",
    "schnet_df = schnet_df.drop_duplicates(subset=['smiles'])\n",
    "\n",
    "get_schnet_data(schnet_df['smiles'].values, 1240./schnet_df[target].values, schnet_df.index.values, save_path=f'data/schnet/{db}/{target}_{split}.db', conf_num=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
